import { ChatOpenAI } from "@langchain/openai";
import { SerpAPI } from "@langchain/community/tools/serpapi";
import { getChatPromptTemplate } from "@/lib/chatPromptTemplates";
import { AutoGPT } from "langchain/experimental/autogpt";
import { OpenAIEmbeddings } from "@langchain/openai";
import { MemoryVectorStore } from "langchain/vectorstores/memory";

const OPENAI_API_KEY = process.env.OPENAI_API_KEY;
export async function callAutoGPT(
  task: string,
) {
  console.log("üîç Calling AutoGPT");
  try {
    const tools = [
      new SerpAPI(process.env.SERPAPI_API_KEY || "", {
        engine: "google",
        hl: "th",
        gl: "th",
      }),
    ]

    const chatModel = new ChatOpenAI({
      model: "gpt-4o",
      temperature: 0.7,
      openAIApiKey: OPENAI_API_KEY,
    });

    const autogpt = AutoGPT.fromLLMAndTools(
      chatModel,
      tools,
      {
        memory: new MemoryVectorStore(new OpenAIEmbeddings()).asRetriever(),
        aiName: "AI ‡∏ú‡∏π‡πâ‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ",
        aiRole: "‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ",
        humanInTheLoop: true,
        maxIterations: 10,
      }
    );
    const response = await autogpt.run([task]);
    console.log("‚úÖ LLM response (no retrieval):", response);
    return response;
  } catch (error) {
    console.error("‚ùå LangChain/OpenAI Error:", error);
    throw new Error("Failed to get AI response");
  }
}
