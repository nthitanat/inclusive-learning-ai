import { ChatOpenAI } from "@langchain/openai";

const OPENAI_API_KEY = process.env.OPENAI_API_KEY;

export async function callSimpleLLM(prompt: string): Promise<string> {
  console.log("ü§ñ Calling Simple LLM");
  try {
    const chatModel = new ChatOpenAI({
      model: "gpt-4o",
      temperature: 0.5,
      openAIApiKey: OPENAI_API_KEY,
    });

    const response = await chatModel.invoke([
      {
        role: "system",
        content: "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÅ‡∏•‡∏∞‡∏ú‡∏π‡πâ‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏≠‡∏ô ‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô"
      },
      {
        role: "user", 
        content: prompt
      }
    ]);
    
    console.log("‚úÖ Simple LLM response:", response.content);
    return response.content as string;
  } catch (error) {
    console.error("‚ùå Simple LLM Error:", error);
    throw new Error("Failed to get AI response");
  }
}
